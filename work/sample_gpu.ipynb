{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b1508ef-58f5-4c26-99cf-76fcb37dc7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from open_interpreter_handler import OpenInterpreterHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0aef1c56-7177-4bf7-bd58-341958c560e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_interpreter = OpenInterpreterHandler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9bd4a5c-e1c1-4522-b285-3830374d1e6b",
   "metadata": {},
   "source": [
    "## 転移学習の方法調査"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3875fcfd-5ff3-4b64-b9e3-21fcd0617476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78eba5dfd29b4926ba42d76c114e04a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "880e747cf4734cd3afc3f3a62bfd2b05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c469550a54ed471f9545cbc445a3ab62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9691896081eb407f8ad616530a29bd84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cddb97ea5f064bc18f76274477c920cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "open_interpreter.chat(\"\"\"\n",
    "以下の調査をお願いします。\n",
    " * pytroch で GPU が使用できるか\n",
    " * GPU の名前\n",
    "\n",
    " また、pytorchはインストール済みです。\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b84342c0-aa83-43f0-86b3-8fa15e718eff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "530e78b1f6fc44e99180479a9b4f97b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d5455ee0ea64515b6b52b56f9d0a732",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf1c7f5b33834297a4cb829fb3c49b71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "open_interpreter.chat(\"\"\"\n",
    "timm の create_model を使用し VGG16 の PreTrain モデルを用意してください。\n",
    "\n",
    "timm, torch, torchvision, cv2 はインストール済みです。\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d1365e3-2e2e-452c-a550-dd3ce5247316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e78b53239c549bba8db65ac6d1ab5df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f8e7f9eeb954303b0aa43788dfbdcb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10aefefd371246a39367bf021a6e73f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d55ee8ba661b41329af12a2b784489c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f3d863de9e045feb860ddb7b8f4f101",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "open_interpreter.chat(\"\"\"\n",
    "用意した model をmodels に保存してください。\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd8d0ddd-75d0-493c-8f58-4a5fa01821c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_interpreter.clear_messages_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cba1a301-a186-452e-a4de-2b35cc3ee077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba03d00c955441029a1719e1246efe4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afac9f9d01944a5ca40aeb7ec96d0b79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d9e99e2dac04a73925e97a2d3acf325",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "057af89fcabe470d8f1782882d8baa10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d5683fdde954d999e8bc099f1316f1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bfa2bd0dca14b5485585e8ac96291d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e10bb53647b94fcdb665290d5a9939cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5c89a23c0284355b15dfd49185f66bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f11fa1ceca234f048161f5049c45d076",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d72427421d9441185fd7f9e4c172020",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c4d10bf2042473a9ecc95df034ff92f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "open_interpreter.chat(\"\"\"\n",
    "CIFAR-10 のデータセットをプロジェクト直下に以下のようなディレクトリ構造で配置しました。\n",
    "```\n",
    "  - datasets\n",
    "    - cifar10\n",
    "      - test\n",
    "        - class1\n",
    "          - 0000.png\n",
    "          - 0001.png\n",
    "          ...\n",
    "          \n",
    "        - class2\n",
    "          ...\n",
    "          \n",
    "      - train\n",
    "        - class1\n",
    "          - 0000.png\n",
    "          - 0001.png\n",
    "          ...\n",
    "          \n",
    "        - class2\n",
    "          ...\n",
    "```\n",
    "\n",
    "CIFAR-10 用の pytorch の CustomDataset を作成してください。\n",
    "Test, Train ともに用意してください。\n",
    "また、画像はすべて使用せず、各クラスで200枚のみ使用してください。\n",
    "glob, cv2 をうまく活用してください。\n",
    "timm, torch, torchvision, cv2 はインストール済みです。\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c0e59475-f838-4c9b-84a8-b810926a1ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_interpreter.clear_messages_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "459a0cba-488b-4690-ab52-f5bcc5734e3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fb81f593a9142f8a58744f3917b6024",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3ad4e3296564eeda52f26b90b137f0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea721999819e4523a10ad47c51ffd760",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b540c484455421b9929a426f22881d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f85eec6359a04aaeb6d6e2ea2eecac62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "open_interpreter.chat(\"\"\"\n",
    "VGG16 の pretrain モデルが ./models/vgg16_pretrain.pt にあります。\n",
    "読み込んでください。\n",
    "また、転移学習できるように 出力を 10クラスに変更してください。\n",
    "timm, torch, torchvision, cv2 はインストール済みです。\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "85e7a1e2-4abf-4e7c-b8b6-f8d8b811e7fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d456aa176ae4f1eada901dc4e884bd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "open_interpreter.chat(\"\"\"\n",
    "このモデルを転移学習させるためのサンプルコードを出力してください。\n",
    "timm, torch, torchvision, cv2 はインストール済みです。\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "36c91123-c77e-4fd2-b38b-b0a5d5c754e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_interpreter.clear_messages_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6d8b48e2-1afc-47e1-a4ce-bc3421530dde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24bebaef96224b09bb15f5a210c8200e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "open_interpreter.chat(\"\"\"\n",
    "以下のコードは、model.head.fc のみ重みが更新されますか？\n",
    "そうでなければその方法を教えてください。\n",
    "\n",
    "\n",
    "import torch                                                                                                    \n",
    "import torch.nn as nn                                                                                           \n",
    "import torch.optim as optim                                                                                     \n",
    "from torch.optim import lr_scheduler                                                                            \n",
    "import torchvision                                                                                              \n",
    "from torchvision import datasets, models, transforms                                                            \n",
    "import timm                                                                                                     \n",
    "import os                                                                                                       \n",
    "                                                                                                               \n",
    "# Load the pre-trained VGG16 model                                                                              \n",
    "model = torch.load('./models/vgg16_pretrain.pt')                                                                \n",
    "                                                                                                               \n",
    "# Change the output layer to 10 classes                                                                         \n",
    "model.head.fc = nn.Linear(4096, 10)                                                                             \n",
    "                                                                                                               \n",
    "# Define a transform to normalize the data                                                                      \n",
    "transform = transforms.Compose([                                                                                \n",
    "   transforms.Resize(256),                                                                                     \n",
    "   transforms.CenterCrop(224),                                                                                 \n",
    "   transforms.ToTensor(),                                                                                      \n",
    "   transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])                                          \n",
    "])                                                                                                              \n",
    "                                                                                                               \n",
    "# Load the training data                                                                                        \n",
    "train_data = datasets.ImageFolder(os.path.join(data_dir, 'train'), transform=transform)                         \n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)                             \n",
    "                                                                                                               \n",
    "# Load the validation data                                                                                      \n",
    "val_data = datasets.ImageFolder(os.path.join(data_dir, 'val'), transform=transform)                             \n",
    "val_loader = torch.utils.data.DataLoader(val_data, batch_size=64)                                               \n",
    "                                                                                                               \n",
    "# Define the criterion and optimizer                                                                            \n",
    "criterion = nn.CrossEntropyLoss()                                                                               \n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)                                               \n",
    "                                                                                                               \n",
    "# Train the model                                                                                               \n",
    "for epoch in range(num_epochs):                                                                                 \n",
    "   for inputs, labels in train_loader:                                                                         \n",
    "       optimizer.zero_grad()                                                                                   \n",
    "       outputs = model(inputs)                                                                                 \n",
    "       loss = criterion(outputs, labels)                                                                       \n",
    "       loss.backward()                                                                                         \n",
    "       optimizer.step()                                                                                        \n",
    "                                                                                                               \n",
    "# Evaluate the model                                                                                            \n",
    "model.eval()                                                                                                    \n",
    "with torch.no_grad():                                                                                           \n",
    "   for inputs, labels in val_loader:                                                                           \n",
    "       outputs = model(inputs)                                                                                 \n",
    "       _, preds = torch.max(outputs, 1)                                                                        \n",
    "       running_corrects += torch.sum(preds == labels.data) \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "278b10ae-9cc7-47ca-9d73-8bc9d55d2dae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27ab2a24afa2402c88ad696907003c75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "open_interpreter.chat(\"\"\"\n",
    "学習済みもモデルを保存したい。方法を教えてください。\n",
    "\n",
    "\n",
    "import torch                                                                                                    \n",
    "import torch.nn as nn                                                                                           \n",
    "import torch.optim as optim                                                                                     \n",
    "from torch.optim import lr_scheduler                                                                            \n",
    "import torchvision                                                                                              \n",
    "from torchvision import datasets, models, transforms                                                            \n",
    "import timm                                                                                                     \n",
    "import os                                                                                                       \n",
    "                                                                                                               \n",
    "# Load the pre-trained VGG16 model                                                                              \n",
    "model = torch.load('./models/vgg16_pretrain.pt')                                                                \n",
    "                                                                                                               \n",
    "# Change the output layer to 10 classes                                                                         \n",
    "model.head.fc = nn.Linear(4096, 10)                                                                             \n",
    "                                                                                                               \n",
    "# Define a transform to normalize the data                                                                      \n",
    "transform = transforms.Compose([                                                                                \n",
    "   transforms.Resize(256),                                                                                     \n",
    "   transforms.CenterCrop(224),                                                                                 \n",
    "   transforms.ToTensor(),                                                                                      \n",
    "   transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])                                          \n",
    "])                                                                                                              \n",
    "                                                                                                               \n",
    "# Load the training data                                                                                        \n",
    "train_data = datasets.ImageFolder(os.path.join(data_dir, 'train'), transform=transform)                         \n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)                             \n",
    "                                                                                                               \n",
    "# Load the validation data                                                                                      \n",
    "val_data = datasets.ImageFolder(os.path.join(data_dir, 'val'), transform=transform)                             \n",
    "val_loader = torch.utils.data.DataLoader(val_data, batch_size=64)                                               \n",
    "                                                                                                               \n",
    "# Define the criterion and optimizer                                                                            \n",
    "criterion = nn.CrossEntropyLoss()                                                                               \n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)                                               \n",
    "                                                                                                               \n",
    "# Train the model                                                                                               \n",
    "for epoch in range(num_epochs):                                                                                 \n",
    "   for inputs, labels in train_loader:                                                                         \n",
    "       optimizer.zero_grad()                                                                                   \n",
    "       outputs = model(inputs)                                                                                 \n",
    "       loss = criterion(outputs, labels)                                                                       \n",
    "       loss.backward()                                                                                         \n",
    "       optimizer.step()                                                                                        \n",
    "                                                                                                               \n",
    "# Evaluate the model                                                                                            \n",
    "model.eval()                                                                                                    \n",
    "with torch.no_grad():                                                                                           \n",
    "   for inputs, labels in val_loader:                                                                           \n",
    "       outputs = model(inputs)                                                                                 \n",
    "       _, preds = torch.max(outputs, 1)                                                                        \n",
    "       running_corrects += torch.sum(preds == labels.data) \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "18ab2198-a41b-4868-a56a-8ea1303f98bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0479102b794430c8bd576e4d979fc45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "open_interpreter.chat(\"\"\"\n",
    "学習済みもモデルをロードするときに pt からモデルの構造もしゅとくできませんか？\n",
    "\n",
    "\n",
    "# Load the model                                                                                                \n",
    "model = TheModelClass(*args, **kwargs)                                                                          \n",
    "model.load_state_dict(torch.load('./models/my_model.pt')) \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d573e96-e729-4d77-986e-edd55313def0",
   "metadata": {},
   "source": [
    "## 転移学習の実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "253d3e8e-1893-4049-9c5f-43c35c9288cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os                                                                                                        \n",
    "import glob                                                                                                      \n",
    "import cv2      \n",
    "import torch    \n",
    "import torch.nn as nn   \n",
    "import torch.optim as optim \n",
    "from torch.optim import lr_scheduler                                                                            \n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader \n",
    "from torchvision import transforms  \n",
    "from torchvision import datasets, models, transforms   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "907699b4-84ee-433c-9023-47c561befdd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bcf23dae-4bb3-4592-9caa-e1baa61516f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (pre_logits): ConvMlp(\n",
       "    (fc1): Conv2d(512, 4096, kernel_size=(7, 7), stride=(1, 1))\n",
       "    (act1): ReLU(inplace=True)\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "    (fc2): Conv2d(4096, 4096, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (act2): ReLU(inplace=True)\n",
       "  )\n",
       "  (head): ClassifierHead(\n",
       "    (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "    (fc): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "    (flatten): Identity()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the pre-trained VGG16 model                                                                               \n",
    "model = torch.load('./models/vgg16_pretrain.pt')                                                                 \n",
    "\n",
    "# Print the model structure                                                                                      \n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "97d992de-12b4-4aac-b936-07c6a86d4262",
   "metadata": {},
   "outputs": [],
   "source": [
    " class CIFAR10Dataset(Dataset):                                                                                   \n",
    "      def __init__(self, root_dir, transform=None, num_images_per_class=200):                                      \n",
    "          self.root_dir = root_dir                                                                                 \n",
    "          self.transform = transform                                                                               \n",
    "          self.num_images_per_class = num_images_per_class                                                         \n",
    "          self.classes = os.listdir(self.root_dir)                                                                 \n",
    "          self.classes.sort()                                                                                      \n",
    "          self.image_paths = []                                                                                    \n",
    "          self.labels = []                                                                                         \n",
    "                                                                                                                   \n",
    "          for i, _class in enumerate(self.classes):                                                                \n",
    "              class_dir = os.path.join(self.root_dir, _class)                                                      \n",
    "              image_files = glob.glob(class_dir + '/*.png')[:self.num_images_per_class]                            \n",
    "              self.image_paths += image_files                                                                      \n",
    "              self.labels += [i] * len(image_files)                                                                \n",
    "                                                                                                                   \n",
    "      def __len__(self):                                                                                           \n",
    "          return len(self.image_paths)\n",
    "\n",
    "      def __getitem__(self, idx):                                                                                      \n",
    "          image_path = self.image_paths[idx]                                                                           \n",
    "          label = self.labels[idx]                                                                                     \n",
    "          image = cv2.imread(image_path)                                                                               \n",
    "          image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)                                                               \n",
    "                                                                                                                       \n",
    "          if self.transform:                                                                                           \n",
    "              image = self.transform(image)                                                                            \n",
    "                                                                                                                       \n",
    "          return image, label   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "edcd92c5-84f5-4ba2-8706-efd50fa9ba6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([                                                                           \n",
    "    transforms.ToPILImage(),                                                                                     \n",
    "    transforms.Resize(256),                                                                                     \n",
    "    transforms.CenterCrop(224),                                                                                 \n",
    "    transforms.ToTensor(),                                                                                                                                                           \n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))                                                       \n",
    "])                                                                                                               \n",
    "                                                                                                               \n",
    "test_transform = transforms.Compose([                                                                            \n",
    "    transforms.ToPILImage(),                                                                                     \n",
    "    transforms.Resize(256),                                                                                     \n",
    "    transforms.CenterCrop(224),                                                                                 \n",
    "    transforms.ToTensor(),                                                                                       \n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))                                                       \n",
    "])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9edb7ff0-ca79-4a9e-85a3-c021f0a43093",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CIFAR10Dataset('/work/datasets/cifar10/train', transform=train_transform)                        \n",
    "test_dataset = CIFAR10Dataset('/work/datasets/cifar10/test', transform=test_transform)                           \n",
    "                                                                                                               \n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)                                            \n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6cabd368-a895-4a84-b075-363b2908f098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (pre_logits): ConvMlp(\n",
       "    (fc1): Conv2d(512, 4096, kernel_size=(7, 7), stride=(1, 1))\n",
       "    (act1): ReLU(inplace=True)\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "    (fc2): Conv2d(4096, 4096, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (act2): ReLU(inplace=True)\n",
       "  )\n",
       "  (head): ClassifierHead(\n",
       "    (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "    (fc): Linear(in_features=4096, out_features=10, bias=True)\n",
       "    (flatten): Identity()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model.head.fc = nn.Linear(4096, 10)\n",
    "for param in model.head.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f5ac82b0-0bf9-4e24-bae8-fa252bf78afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the criterion and optimizer                                                                            \n",
    "criterion = nn.CrossEntropyLoss()                                                                               \n",
    "\n",
    "# Pass only the parameters of model.head.fc to the optimizer                                                    \n",
    "optimizer = optim.SGD(model.head.fc.parameters(), lr=0.001, momentum=0.9)                                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "79e0b701-efcd-4cf6-b9fe-a4fcbecbd96e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training batch 1\n",
      "Training batch 2\n",
      "Training batch 3\n",
      "Training batch 4\n",
      "Training batch 5\n",
      "Training batch 6\n",
      "Training batch 7\n",
      "Training batch 8\n",
      "Training batch 9\n",
      "Training batch 10\n",
      "Training batch 11\n",
      "Training batch 12\n",
      "Training batch 13\n",
      "Training batch 14\n",
      "Training batch 15\n",
      "Training batch 16\n",
      "Training batch 17\n",
      "Training batch 18\n",
      "Training batch 19\n",
      "Training batch 20\n",
      "Training batch 21\n",
      "Training batch 22\n",
      "Training batch 23\n",
      "Training batch 24\n",
      "Training batch 25\n",
      "Training batch 26\n",
      "Training batch 27\n",
      "Training batch 28\n",
      "Training batch 29\n",
      "Training batch 30\n",
      "Training batch 31\n",
      "Training batch 32\n",
      "Testing batch 1\n",
      "Testing batch 2\n",
      "Testing batch 3\n",
      "Testing batch 4\n",
      "Testing batch 5\n",
      "Testing batch 6\n",
      "Testing batch 7\n",
      "Testing batch 8\n",
      "Testing batch 9\n",
      "Testing batch 10\n",
      "Testing batch 11\n",
      "Testing batch 12\n",
      "Testing batch 13\n",
      "Testing batch 14\n",
      "Testing batch 15\n",
      "Testing batch 16\n",
      "Testing batch 17\n",
      "Testing batch 18\n",
      "Testing batch 19\n",
      "Testing batch 20\n",
      "Testing batch 21\n",
      "Testing batch 22\n",
      "Testing batch 23\n",
      "Testing batch 24\n",
      "Testing batch 25\n",
      "Testing batch 26\n",
      "Testing batch 27\n",
      "Testing batch 28\n",
      "Testing batch 29\n",
      "Testing batch 30\n",
      "Testing batch 31\n",
      "Testing batch 32\n",
      "Epoch 1/10 Test Accuracy: 0.6130\n",
      "\n",
      "Training batch 1\n",
      "Training batch 2\n",
      "Training batch 3\n",
      "Training batch 4\n",
      "Training batch 5\n",
      "Training batch 6\n",
      "Training batch 7\n",
      "Training batch 8\n",
      "Training batch 9\n",
      "Training batch 10\n",
      "Training batch 11\n",
      "Training batch 12\n",
      "Training batch 13\n",
      "Training batch 14\n",
      "Training batch 15\n",
      "Training batch 16\n",
      "Training batch 17\n",
      "Training batch 18\n",
      "Training batch 19\n",
      "Training batch 20\n",
      "Training batch 21\n",
      "Training batch 22\n",
      "Training batch 23\n",
      "Training batch 24\n",
      "Training batch 25\n",
      "Training batch 26\n",
      "Training batch 27\n",
      "Training batch 28\n",
      "Training batch 29\n",
      "Training batch 30\n",
      "Training batch 31\n",
      "Training batch 32\n",
      "Testing batch 1\n",
      "Testing batch 2\n",
      "Testing batch 3\n",
      "Testing batch 4\n",
      "Testing batch 5\n",
      "Testing batch 6\n",
      "Testing batch 7\n",
      "Testing batch 8\n",
      "Testing batch 9\n",
      "Testing batch 10\n",
      "Testing batch 11\n",
      "Testing batch 12\n",
      "Testing batch 13\n",
      "Testing batch 14\n",
      "Testing batch 15\n",
      "Testing batch 16\n",
      "Testing batch 17\n",
      "Testing batch 18\n",
      "Testing batch 19\n",
      "Testing batch 20\n",
      "Testing batch 21\n",
      "Testing batch 22\n",
      "Testing batch 23\n",
      "Testing batch 24\n",
      "Testing batch 25\n",
      "Testing batch 26\n",
      "Testing batch 27\n",
      "Testing batch 28\n",
      "Testing batch 29\n",
      "Testing batch 30\n",
      "Testing batch 31\n",
      "Testing batch 32\n",
      "Epoch 2/10 Test Accuracy: 0.6565\n",
      "\n",
      "Training batch 1\n",
      "Training batch 2\n",
      "Training batch 3\n",
      "Training batch 4\n",
      "Training batch 5\n",
      "Training batch 6\n",
      "Training batch 7\n",
      "Training batch 8\n",
      "Training batch 9\n",
      "Training batch 10\n",
      "Training batch 11\n",
      "Training batch 12\n",
      "Training batch 13\n",
      "Training batch 14\n",
      "Training batch 15\n",
      "Training batch 16\n",
      "Training batch 17\n",
      "Training batch 18\n",
      "Training batch 19\n",
      "Training batch 20\n",
      "Training batch 21\n",
      "Training batch 22\n",
      "Training batch 23\n",
      "Training batch 24\n",
      "Training batch 25\n",
      "Training batch 26\n",
      "Training batch 27\n",
      "Training batch 28\n",
      "Training batch 29\n",
      "Training batch 30\n",
      "Training batch 31\n",
      "Training batch 32\n",
      "Testing batch 1\n",
      "Testing batch 2\n",
      "Testing batch 3\n",
      "Testing batch 4\n",
      "Testing batch 5\n",
      "Testing batch 6\n",
      "Testing batch 7\n",
      "Testing batch 8\n",
      "Testing batch 9\n",
      "Testing batch 10\n",
      "Testing batch 11\n",
      "Testing batch 12\n",
      "Testing batch 13\n",
      "Testing batch 14\n",
      "Testing batch 15\n",
      "Testing batch 16\n",
      "Testing batch 17\n",
      "Testing batch 18\n",
      "Testing batch 19\n",
      "Testing batch 20\n",
      "Testing batch 21\n",
      "Testing batch 22\n",
      "Testing batch 23\n",
      "Testing batch 24\n",
      "Testing batch 25\n",
      "Testing batch 26\n",
      "Testing batch 27\n",
      "Testing batch 28\n",
      "Testing batch 29\n",
      "Testing batch 30\n",
      "Testing batch 31\n",
      "Testing batch 32\n",
      "Epoch 3/10 Test Accuracy: 0.6720\n",
      "\n",
      "Training batch 1\n",
      "Training batch 2\n",
      "Training batch 3\n",
      "Training batch 4\n",
      "Training batch 5\n",
      "Training batch 6\n",
      "Training batch 7\n",
      "Training batch 8\n",
      "Training batch 9\n",
      "Training batch 10\n",
      "Training batch 11\n",
      "Training batch 12\n",
      "Training batch 13\n",
      "Training batch 14\n",
      "Training batch 15\n",
      "Training batch 16\n",
      "Training batch 17\n",
      "Training batch 18\n",
      "Training batch 19\n",
      "Training batch 20\n",
      "Training batch 21\n",
      "Training batch 22\n",
      "Training batch 23\n",
      "Training batch 24\n",
      "Training batch 25\n",
      "Training batch 26\n",
      "Training batch 27\n",
      "Training batch 28\n",
      "Training batch 29\n",
      "Training batch 30\n",
      "Training batch 31\n",
      "Training batch 32\n",
      "Testing batch 1\n",
      "Testing batch 2\n",
      "Testing batch 3\n",
      "Testing batch 4\n",
      "Testing batch 5\n",
      "Testing batch 6\n",
      "Testing batch 7\n",
      "Testing batch 8\n",
      "Testing batch 9\n",
      "Testing batch 10\n",
      "Testing batch 11\n",
      "Testing batch 12\n",
      "Testing batch 13\n",
      "Testing batch 14\n",
      "Testing batch 15\n",
      "Testing batch 16\n",
      "Testing batch 17\n",
      "Testing batch 18\n",
      "Testing batch 19\n",
      "Testing batch 20\n",
      "Testing batch 21\n",
      "Testing batch 22\n",
      "Testing batch 23\n",
      "Testing batch 24\n",
      "Testing batch 25\n",
      "Testing batch 26\n",
      "Testing batch 27\n",
      "Testing batch 28\n",
      "Testing batch 29\n",
      "Testing batch 30\n",
      "Testing batch 31\n",
      "Testing batch 32\n",
      "Epoch 4/10 Test Accuracy: 0.6800\n",
      "\n",
      "Training batch 1\n",
      "Training batch 2\n",
      "Training batch 3\n",
      "Training batch 4\n",
      "Training batch 5\n",
      "Training batch 6\n",
      "Training batch 7\n",
      "Training batch 8\n",
      "Training batch 9\n",
      "Training batch 10\n",
      "Training batch 11\n",
      "Training batch 12\n",
      "Training batch 13\n",
      "Training batch 14\n",
      "Training batch 15\n",
      "Training batch 16\n",
      "Training batch 17\n",
      "Training batch 18\n",
      "Training batch 19\n",
      "Training batch 20\n",
      "Training batch 21\n",
      "Training batch 22\n",
      "Training batch 23\n",
      "Training batch 24\n",
      "Training batch 25\n",
      "Training batch 26\n",
      "Training batch 27\n",
      "Training batch 28\n",
      "Training batch 29\n",
      "Training batch 30\n",
      "Training batch 31\n",
      "Training batch 32\n",
      "Testing batch 1\n",
      "Testing batch 2\n",
      "Testing batch 3\n",
      "Testing batch 4\n",
      "Testing batch 5\n",
      "Testing batch 6\n",
      "Testing batch 7\n",
      "Testing batch 8\n",
      "Testing batch 9\n",
      "Testing batch 10\n",
      "Testing batch 11\n",
      "Testing batch 12\n",
      "Testing batch 13\n",
      "Testing batch 14\n",
      "Testing batch 15\n",
      "Testing batch 16\n",
      "Testing batch 17\n",
      "Testing batch 18\n",
      "Testing batch 19\n",
      "Testing batch 20\n",
      "Testing batch 21\n",
      "Testing batch 22\n",
      "Testing batch 23\n",
      "Testing batch 24\n",
      "Testing batch 25\n",
      "Testing batch 26\n",
      "Testing batch 27\n",
      "Testing batch 28\n",
      "Testing batch 29\n",
      "Testing batch 30\n",
      "Testing batch 31\n",
      "Testing batch 32\n",
      "Epoch 5/10 Test Accuracy: 0.6925\n",
      "\n",
      "Training batch 1\n",
      "Training batch 2\n",
      "Training batch 3\n",
      "Training batch 4\n",
      "Training batch 5\n",
      "Training batch 6\n",
      "Training batch 7\n",
      "Training batch 8\n",
      "Training batch 9\n",
      "Training batch 10\n",
      "Training batch 11\n",
      "Training batch 12\n",
      "Training batch 13\n",
      "Training batch 14\n",
      "Training batch 15\n",
      "Training batch 16\n",
      "Training batch 17\n",
      "Training batch 18\n",
      "Training batch 19\n",
      "Training batch 20\n",
      "Training batch 21\n",
      "Training batch 22\n",
      "Training batch 23\n",
      "Training batch 24\n",
      "Training batch 25\n",
      "Training batch 26\n",
      "Training batch 27\n",
      "Training batch 28\n",
      "Training batch 29\n",
      "Training batch 30\n",
      "Training batch 31\n",
      "Training batch 32\n",
      "Testing batch 1\n",
      "Testing batch 2\n",
      "Testing batch 3\n",
      "Testing batch 4\n",
      "Testing batch 5\n",
      "Testing batch 6\n",
      "Testing batch 7\n",
      "Testing batch 8\n",
      "Testing batch 9\n",
      "Testing batch 10\n",
      "Testing batch 11\n",
      "Testing batch 12\n",
      "Testing batch 13\n",
      "Testing batch 14\n",
      "Testing batch 15\n",
      "Testing batch 16\n",
      "Testing batch 17\n",
      "Testing batch 18\n",
      "Testing batch 19\n",
      "Testing batch 20\n",
      "Testing batch 21\n",
      "Testing batch 22\n",
      "Testing batch 23\n",
      "Testing batch 24\n",
      "Testing batch 25\n",
      "Testing batch 26\n",
      "Testing batch 27\n",
      "Testing batch 28\n",
      "Testing batch 29\n",
      "Testing batch 30\n",
      "Testing batch 31\n",
      "Testing batch 32\n",
      "Epoch 6/10 Test Accuracy: 0.7075\n",
      "\n",
      "Training batch 1\n",
      "Training batch 2\n",
      "Training batch 3\n",
      "Training batch 4\n",
      "Training batch 5\n",
      "Training batch 6\n",
      "Training batch 7\n",
      "Training batch 8\n",
      "Training batch 9\n",
      "Training batch 10\n",
      "Training batch 11\n",
      "Training batch 12\n",
      "Training batch 13\n",
      "Training batch 14\n",
      "Training batch 15\n",
      "Training batch 16\n",
      "Training batch 17\n",
      "Training batch 18\n",
      "Training batch 19\n",
      "Training batch 20\n",
      "Training batch 21\n",
      "Training batch 22\n",
      "Training batch 23\n",
      "Training batch 24\n",
      "Training batch 25\n",
      "Training batch 26\n",
      "Training batch 27\n",
      "Training batch 28\n",
      "Training batch 29\n",
      "Training batch 30\n",
      "Training batch 31\n",
      "Training batch 32\n",
      "Testing batch 1\n",
      "Testing batch 2\n",
      "Testing batch 3\n",
      "Testing batch 4\n",
      "Testing batch 5\n",
      "Testing batch 6\n",
      "Testing batch 7\n",
      "Testing batch 8\n",
      "Testing batch 9\n",
      "Testing batch 10\n",
      "Testing batch 11\n",
      "Testing batch 12\n",
      "Testing batch 13\n",
      "Testing batch 14\n",
      "Testing batch 15\n",
      "Testing batch 16\n",
      "Testing batch 17\n",
      "Testing batch 18\n",
      "Testing batch 19\n",
      "Testing batch 20\n",
      "Testing batch 21\n",
      "Testing batch 22\n",
      "Testing batch 23\n",
      "Testing batch 24\n",
      "Testing batch 25\n",
      "Testing batch 26\n",
      "Testing batch 27\n",
      "Testing batch 28\n",
      "Testing batch 29\n",
      "Testing batch 30\n",
      "Testing batch 31\n",
      "Testing batch 32\n",
      "Epoch 7/10 Test Accuracy: 0.7010\n",
      "\n",
      "Training batch 1\n",
      "Training batch 2\n",
      "Training batch 3\n",
      "Training batch 4\n",
      "Training batch 5\n",
      "Training batch 6\n",
      "Training batch 7\n",
      "Training batch 8\n",
      "Training batch 9\n",
      "Training batch 10\n",
      "Training batch 11\n",
      "Training batch 12\n",
      "Training batch 13\n",
      "Training batch 14\n",
      "Training batch 15\n",
      "Training batch 16\n",
      "Training batch 17\n",
      "Training batch 18\n",
      "Training batch 19\n",
      "Training batch 20\n",
      "Training batch 21\n",
      "Training batch 22\n",
      "Training batch 23\n",
      "Training batch 24\n",
      "Training batch 25\n",
      "Training batch 26\n",
      "Training batch 27\n",
      "Training batch 28\n",
      "Training batch 29\n",
      "Training batch 30\n",
      "Training batch 31\n",
      "Training batch 32\n",
      "Testing batch 1\n",
      "Testing batch 2\n",
      "Testing batch 3\n",
      "Testing batch 4\n",
      "Testing batch 5\n",
      "Testing batch 6\n",
      "Testing batch 7\n",
      "Testing batch 8\n",
      "Testing batch 9\n",
      "Testing batch 10\n",
      "Testing batch 11\n",
      "Testing batch 12\n",
      "Testing batch 13\n",
      "Testing batch 14\n",
      "Testing batch 15\n",
      "Testing batch 16\n",
      "Testing batch 17\n",
      "Testing batch 18\n",
      "Testing batch 19\n",
      "Testing batch 20\n",
      "Testing batch 21\n",
      "Testing batch 22\n",
      "Testing batch 23\n",
      "Testing batch 24\n",
      "Testing batch 25\n",
      "Testing batch 26\n",
      "Testing batch 27\n",
      "Testing batch 28\n",
      "Testing batch 29\n",
      "Testing batch 30\n",
      "Testing batch 31\n",
      "Testing batch 32\n",
      "Epoch 8/10 Test Accuracy: 0.7140\n",
      "\n",
      "Training batch 1\n",
      "Training batch 2\n",
      "Training batch 3\n",
      "Training batch 4\n",
      "Training batch 5\n",
      "Training batch 6\n",
      "Training batch 7\n",
      "Training batch 8\n",
      "Training batch 9\n",
      "Training batch 10\n",
      "Training batch 11\n",
      "Training batch 12\n",
      "Training batch 13\n",
      "Training batch 14\n",
      "Training batch 15\n",
      "Training batch 16\n",
      "Training batch 17\n",
      "Training batch 18\n",
      "Training batch 19\n",
      "Training batch 20\n",
      "Training batch 21\n",
      "Training batch 22\n",
      "Training batch 23\n",
      "Training batch 24\n",
      "Training batch 25\n",
      "Training batch 26\n",
      "Training batch 27\n",
      "Training batch 28\n",
      "Training batch 29\n",
      "Training batch 30\n",
      "Training batch 31\n",
      "Training batch 32\n",
      "Testing batch 1\n",
      "Testing batch 2\n",
      "Testing batch 3\n",
      "Testing batch 4\n",
      "Testing batch 5\n",
      "Testing batch 6\n",
      "Testing batch 7\n",
      "Testing batch 8\n",
      "Testing batch 9\n",
      "Testing batch 10\n",
      "Testing batch 11\n",
      "Testing batch 12\n",
      "Testing batch 13\n",
      "Testing batch 14\n",
      "Testing batch 15\n",
      "Testing batch 16\n",
      "Testing batch 17\n",
      "Testing batch 18\n",
      "Testing batch 19\n",
      "Testing batch 20\n",
      "Testing batch 21\n",
      "Testing batch 22\n",
      "Testing batch 23\n",
      "Testing batch 24\n",
      "Testing batch 25\n",
      "Testing batch 26\n",
      "Testing batch 27\n",
      "Testing batch 28\n",
      "Testing batch 29\n",
      "Testing batch 30\n",
      "Testing batch 31\n",
      "Testing batch 32\n",
      "Epoch 9/10 Test Accuracy: 0.7135\n",
      "\n",
      "Training batch 1\n",
      "Training batch 2\n",
      "Training batch 3\n",
      "Training batch 4\n",
      "Training batch 5\n",
      "Training batch 6\n",
      "Training batch 7\n",
      "Training batch 8\n",
      "Training batch 9\n",
      "Training batch 10\n",
      "Training batch 11\n",
      "Training batch 12\n",
      "Training batch 13\n",
      "Training batch 14\n",
      "Training batch 15\n",
      "Training batch 16\n",
      "Training batch 17\n",
      "Training batch 18\n",
      "Training batch 19\n",
      "Training batch 20\n",
      "Training batch 21\n",
      "Training batch 22\n",
      "Training batch 23\n",
      "Training batch 24\n",
      "Training batch 25\n",
      "Training batch 26\n",
      "Training batch 27\n",
      "Training batch 28\n",
      "Training batch 29\n",
      "Training batch 30\n",
      "Training batch 31\n",
      "Training batch 32\n",
      "Testing batch 1\n",
      "Testing batch 2\n",
      "Testing batch 3\n",
      "Testing batch 4\n",
      "Testing batch 5\n",
      "Testing batch 6\n",
      "Testing batch 7\n",
      "Testing batch 8\n",
      "Testing batch 9\n",
      "Testing batch 10\n",
      "Testing batch 11\n",
      "Testing batch 12\n",
      "Testing batch 13\n",
      "Testing batch 14\n",
      "Testing batch 15\n",
      "Testing batch 16\n",
      "Testing batch 17\n",
      "Testing batch 18\n",
      "Testing batch 19\n",
      "Testing batch 20\n",
      "Testing batch 21\n",
      "Testing batch 22\n",
      "Testing batch 23\n",
      "Testing batch 24\n",
      "Testing batch 25\n",
      "Testing batch 26\n",
      "Testing batch 27\n",
      "Testing batch 28\n",
      "Testing batch 29\n",
      "Testing batch 30\n",
      "Testing batch 31\n",
      "Testing batch 32\n",
      "Epoch 10/10 Test Accuracy: 0.7110\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    count = 0\n",
    "    for inputs, labels in train_loader:\n",
    "        count += 1\n",
    "        print(f\"Training batch {count}\")\n",
    "        \n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    # Testing phase after each epoch\n",
    "    model.eval()\n",
    "    count = 0\n",
    "    running_corrects = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            count += 1\n",
    "            print(f\"Testing batch {count}\")\n",
    "            \n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "    \n",
    "    # Calculate and print accuracy for the current epoch\n",
    "    epoch_accuracy = running_corrects.double() / len(test_loader.dataset)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} Test Accuracy: {epoch_accuracy:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8f22982a-58fc-440b-81dc-a79c130f4fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, './models/vgg16_finetuned.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
